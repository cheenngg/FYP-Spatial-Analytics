{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076aab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_her_infogram(x_cal, y_cal, z_cal, her):\n",
    "    # function to extract the Spatial structure of the data\n",
    "    # -------------- Input --------------\n",
    "    # - x_cal     [N,1]   x coordidates of the calibration set\n",
    "    # - y_cal     [N,1]   y coordidates of the calibration set\n",
    "    # - z_cal     [N,1]   z values of the calibration set (variable under study)\n",
    "    # - her       struct  structure cointaining model definitions\n",
    "    # -------------- Output --------------\n",
    "    # - her       struct  structure cointaining model definitions\n",
    "    # -------------- Version --------------\n",
    "    # - 2020/04/10 Stephanie Thiesen: intial version\n",
    "    # -------------- Script --------------\n",
    "    # Geo1: Spatial Characterization\n",
    "    # step 1: get diff_z as a function of the distance \n",
    "    # calculate the euclidean distance and the difference between all point pairs\n",
    "    zm_res_ = np.min(np.diff(np.unique(z_cal))) # smallest Z resolution\n",
    "    her.n_bins_z_per_bin_shift = min(100, round(0+her.binwidth_z / zm_res_)) # limit to 100 or binwidth_shift = 1 (in the case where all zm are integers)\n",
    "    her.binwidth_shift = her.binwidth_z / her.n_bins_z_per_bin_shift\n",
    "    her.mat_euc_distance_xy = np.empty((len(x_cal), len(x_cal))) # matrix for the distance between 2 pair points\n",
    "    her.mat_diff_z = np.empty((len(z_cal), len(z_cal))) # matrix for the diff_z \n",
    "    for i in range(len(x_cal)): # repeat to each east coordinates (x)\n",
    "        for j in range(len(x_cal)): # repeat to each north coordinates (y)\n",
    "            her.mat_euc_distance_xy[i,j] = f_euclidean_dist(x_cal[i], y_cal[i], x_cal[j], y_cal[j]) # calculate the euclidean distance\n",
    "            her.mat_diff_z[i,j] = f_diff(z_cal[i], z_cal[j]) # calculate the diff_z\n",
    "    \n",
    "    # step 2: define the distance classes (lag)\n",
    "    her.n_lag = np.ceil(np.max(her.mat_euc_distance_xy) / her.lag_dist) # total number of classes\n",
    "    her.edges_distance_classes = np.arange(0, her.lag_dist*(her.n_lag+1), her.lag_dist) # edges of the distance classes or DEFINE  it\n",
    "    \n",
    "    her.bin_centers_distance_classes = np.empty(her.n_lag) # bin centers of the distance classes\n",
    "    # check empty classes\n",
    "    count = 0\n",
    "    her.emptyclass = []\n",
    "    for i in range(her.n_lag): # for each class\n",
    "        idx = np.logical_and(her.mat_euc_distance_xy > her.edges_distance_classes[i], her.mat_euc_distance_xy <= her.edges_distance_classes[i+1]) # find the diff_z within the current lag class\n",
    "        her.bin_centers_distance_classes[i] = (her.edges_distance_classes[i] + her.edges_distance_classes[i+1])/2\n",
    "        if np.sum(idx) == 0:\n",
    "            her.emptyclass.append(i)\n",
    "    \n",
    "    if len(her.emptyclass) > 0: # if we have empty bins, inform\n",
    "        str = 'Atention! There are empty distance classes (' + ', '.join(map(str, her.emptyclass)) + '). Consider increase the lag or bin width to fill the classes into the range.'\n",
    "        print(str)\n",
    "    \n",
    "    # step 3: compute bin edges\n",
    "    max_diff_z = np.max(her.mat_diff_z)\n",
    "    n_bins = 2*np.floor(max_diff_z/her.binwidth + 1) # symmetric\n",
    "    mini = -n_bins/2*her.binwidth\n",
    "    maxi =  n_bins/2*her.binwidth\n",
    "    her.edges_diff_z = np.linspace(mini, maxi, n_bins+1) # edges of the diff_z pmf\n",
    "    her.n_bins_shift = 2*np.floor(max_diff_z/her.binwidth_shift + 1) # symmetric\n",
    "    mini = -her.n_bins_shift/2*her.binwidth_shift\n",
    "    maxi =  her.n_bins_shift/2*her.binwidth_shift\n",
    "    her.edges_diff_z_shift = np.linspace(mini, maxi, her.n_bins_shift+1) # edges of the smaller diff_z pmf\n",
    "    \n",
    "    # step 4: Compute delta_z PMF for the full dataset\n",
    "    idx = her.mat_euc_distance_xy > 0 # ignore the index of the observation in relation to itself\n",
    "    her.obs_diff_z = her.mat_diff_z[idx] # take the diff_z observations\n",
    "    pmf_diff_z_all_obs_withemptybins, _ = np.histogram(her.obs_diff_z, bins=her.edges_diff_z, density=True)\n",
    "    countpmf_diff_z_all_obs, _ = np.histogram(her.obs_diff_z, bins=her.edges_diff_z)\n",
    "    countpmf_diff_z_all_obs_plus1 = countpmf_diff_z_all_obs + 1 # avoiding empty bins (PLUS 1 in each bin)\n",
    "    pmf_diff_z_all_obs = countpmf_diff_z_all_obs_plus1 / np.sum(countpmf_diff_z_all_obs_plus1)\n",
    "    prob_min = 1/(len(her.obs_diff_z))\n",
    "    \n",
    "    countpmf_diff_z_all_obs_shift, _ = np.histogram(her.obs_diff_z, bins=her.edges_diff_z_shift)\n",
    "    countpmf_diff_z_all_obs_shift_plus1 = countpmf_diff_z_all_obs_shift + 1/her.n_bins_z_per_bin_shift # avoiding empty bins (PLUS 1/n in each bin)\n",
    "    countpmf_diff_z_all_obs_shift_plus1 = np.concatenate(([1/her.n_bins_z_per_bin_shift], countpmf_diff_z_all_obs_shift_plus1)) # add empty bin in beginning\n",
    "    pmf_diff_z_all_obs_shift = countpmf_diff_z_all_obs_shift_plus1 / np.sum(countpmf_diff_z_all_obs_shift_plus1)\n",
    "    prob_min_shift = prob_min/her.n_bins_z_per_bin_shift\n",
    "    \n",
    "    # check probabilities sum to 1\n",
    "    if np.abs(np.sum(pmf_diff_z_all_obs) - 1) > .00001:\n",
    "        raise ValueError('Probablities dont sum to 1.')\n",
    "    \n",
    "    if np.abs(np.sum(pmf_diff_z_all_obs_shift) - 1) > .00001:\n",
    "        raise ValueError('Probablities dont sum to 1.')\n",
    "    \n",
    "    # step 5: Calculate the delta_z PMF by distance class\n",
    "    # address delta_z observations to its distance classes\n",
    "    obs_diff_z_by_class = []\n",
    "    pmf_diff_z_by_class_obs_withemptybins = np.empty((len(her.edges_distance_classes)-1, n_bins))\n",
    "    pmf_diff_z_by_class_obs = np.empty((len(her.edges_distance_classes)-1, n_bins)) # diff_z PMF by lag class (each row is one class, the columns are the probability of the diff_z bins)\n",
    "    pmf_diff_z_by_class_obs_shift_withemptybins = np.empty((len(her.edges_distance_classes)-1, her.n_bins_shift))\n",
    "    pmf_diff_z_by_class_obs_shift = np.empty((len(her.edges_distance_classes)-1, her.n_bins_shift+1)) # diff_z PMF by lag class (each row is one class, the columns are the probability of the diff_z bins)\n",
    "    for i in range(len(her.edges_distance_classes)-1): # for each class\n",
    "        idx = np.logical_and(her.mat_euc_distance_xy > her.edges_distance_classes[i], her.mat_euc_distance_xy <= her.edges_distance_classes[i+1]) # find the diff_z within the current lag class\n",
    "        obs_diff_z_by_class.append(her.mat_diff_z[idx]) # save the diff_z \n",
    "        pmf_diff_z_by_class_obs_withemptybins[i], _ = np.histogram(obs_diff_z_by_class[i], bins=her.edges_diff_z, density=True)\n",
    "        pmf_diff_z_by_class_obs[i] = pmf_diff_z_by_class_obs_withemptybins[i] + prob_min\n",
    "        pmf_diff_z_by_class_obs[i] = pmf_diff_z_by_class_obs[i] / np.sum(pmf_diff_z_by_class_obs[i]) # normalization\n",
    "        pmf_diff_z_by_class_obs_shift_withemptybins[i], _ = np.histogram(obs_diff_z_by_class[i], bins=her.edges_diff_z_shift, density=True)\n",
    "        pmf_diff_z_by_class_obs_shift[i,1:] = pmf_diff_z_by_class_obs_shift_withemptybins[i] + prob_min_shift\n",
    "        pmf_diff_z_by_class_obs_shift[i,1:] = pmf_diff_z_by_class_obs_shift[i,1:] / np.sum(pmf_diff_z_by_class_obs_shift[i,1:])\n",
    "    \n",
    "    pmf_diff_z_by_class_obs_shift[:,0] = prob_min_shift # add empty bin in beginning\n",
    "    \n",
    "    # check probabilities sum to 1\n",
    "    for i in range(len(her.edges_distance_classes)-1): # for each class\n",
    "        if np.abs(np.sum(pmf_diff_z_by_class_obs[i]) - 1) > .00001:\n",
    "            raise ValueError('Probablities dont sum to 1.')\n",
    "        \n",
    "        if np.abs(np.sum(pmf_diff_z_by_class_obs_shift[i,1:]) - 1) > .00001:\n",
    "            raise ValueError('Probablities dont sum to 1.')\n",
    "    \n",
    "    # step 6: Entropy\n",
    "    # calculate the entropy of the delta_z PMFs for the full dataset and for the distance classes \n",
    "    her.H_diff_z = f_entropy(pmf_diff_z_all_obs) # entropy of the diff_z PMF of the full dataset\n",
    "    her.H_diff_z_by_class = np.empty((len(her.edges_distance_classes)-1,1)) # vector for the entropy of the diff_z PMF by lag classes \n",
    "    for i in range(len(her.edges_distance_classes)-1): # for each lag class\n",
    "        her.H_diff_z_by_class[i] = f_entropy(pmf_diff_z_by_class_obs[i]) # calculate the entropy\n",
    "    \n",
    "    # step 7: Define the info RANGE, and associate delta_z PMF of the full dataset to the distance classes beyond the range\n",
    "    # calculate the PMF of the full dataset where the class entropy > full dataset entropy \n",
    "    # info RANGE: limit where the entropy of the lag class is greater than the entropy of the full dataset\n",
    "    if her.H_diff_z > her.H_diff_z_by_class[~np.isnan(her.H_diff_z_by_class)].any():\n",
    "        her.n_classes_limit = 20 # DEFINE it looking at the infogram\n",
    "        her.H_lim = her.H_diff_z_by_class[her.n_classes_limit]\n",
    "        her.n_classes_range = np.where(her.H_diff_z_by_class > her.H_lim)[0][0]\n",
    "    else:\n",
    "        her.H_lim = her.H_diff_z\n",
    "        her.n_classes_range = np.where(her.H_diff_z_by_class > her.H_lim)[0][0] # number of distance classes inside the range + full dataset\n",
    "    \n",
    "    her.edges_distance_classes_range = np.array([0]) # edges of distance classes considering the range (starting in zero meters)\n",
    "    her.bin_centers_distance_classes_range = np.empty(0) # bin centers of the distance classes\n",
    "    her.pmf_diff_z_by_class_obs_range = np.empty((0, n_bins)) # diff_z PMF by lag class considering the range (each row is one class, the columns are the probability of the diff_z bins)\n",
    "    her.H_diff_z_by_class_range = np.empty(0) # entropy of the delta_z PMF by lag classes inside the range + full dataset\n",
    "    obs_diff_z_by_class_range = [] # observations of diff_z by lag class considering the range (each cell is one lag class) \n",
    "    for i in range(pmf_diff_z_by_class_obs.shape[0]): # for each class\n",
    "        if her.H_diff_z_by_class[i] > her.H_lim: # stop if the entropy of the lag class is greater than the entropy of the full dataset (or a defined one)\n",
    "            break\n",
    "        else:\n",
    "            her.pmf_diff_z_by_class_obs_range = np.vstack((her.pmf_diff_z_by_class_obs_range, pmf_diff_z_by_class_obs[i])) # save the diff_z PMF\n",
    "            her.pmf_diff_z_by_class_obs_range_shift = np.vstack((her.pmf_diff_z_by_class_obs_range_shift, pmf_diff_z_by_class_obs_shift[i])) # save the diff_z PMF\n",
    "            her.edges_distance_classes_range = np.append(her.edges_distance_classes_range, her.edges_distance_classes[i+1]) # save the edge of the distance class   \n",
    "            her.H_diff_z_by_class_range = np.append(her.H_diff_z_by_class_range, her.H_diff_z_by_class[i]) # save the entropy of the diff_z PMF\n",
    "            obs_diff_z_by_class_range.append(obs_diff_z_by_class[i]) # save the diff_z observation\n",
    "    \n",
    "    # create a last distance class and associate to it \n",
    "    her.pmf_diff_z_by_class_obs_range = np.vstack((her.pmf_diff_z_by_class_obs_range, pmf_diff_z_all_obs)) # diff_z PMF of the full dataset\n",
    "    her.pmf_diff_z_by_class_obs_range_shift = np.vstack((her.pmf_diff_z_by_class_obs_range_shift, pmf_diff_z_all_obs_shift)) # diff_z PMF of the full dataset\n",
    "    her.edges_distance_classes_range = np.append(her.edges_distance_classes_range, her.edges_distance_classes[-1]) # the right edge of the distance class \n",
    "    her.H_diff_z_by_class_range = np.append(her.H_diff_z_by_class_range, her.H_diff_z) # the entropy of the diff_z PMF of the full dataset\n",
    "    obs_diff_z_by_class_range.append(her.obs_diff_z) # the diff_z of the full dataset\n",
    "    \n",
    "    # calculate bin centers of the distance classes\n",
    "    her.bin_centers_distance_classes_range = 1/2 * (her.edges_distance_classes_range[:-1] + her.edges_distance_classes_range[1:])\n",
    "    \n",
    "    # distribution of the # of pairs by class (used for the histogram construction)\n",
    "    her.n_pairs_by_class = np.empty(her.n_lag)\n",
    "    for i in range(her.n_lag):\n",
    "        her.n_pairs_by_class[i] = len(obs_diff_z_by_class[i])\n",
    "    \n",
    "    if np.isnan(np.sum(her.pmf_diff_z_by_class_obs_range)):\n",
    "        str = 'Atention! There are no histograms for \\Deltaz in the range (classes without histogram: ' + ', '.join(map(str, np.where(np.sum(her.pmf_diff_z_by_class_obs_range, axis=1) != 1)[0])) + '). Interpolation not possivel. Consider increase \\Deltaz binwidth.'\n",
    "        print(str)\n",
    "    \n",
    "    # For Geo2: define edges of Z \n",
    "    max_z = np.max(z_cal)\n",
    "    min_z = np.min(z_cal)\n",
    "    max_diff_z = her.edges_diff_z_shift[-1]\n",
    "    min_diff_z = her.edges_diff_z_shift[0]\n",
    "    # compute bin edges\n",
    "    n_bins_left = -np.floor((min_diff_z + min_z)/ her.binwidth_z)\n",
    "    n_bins_right = np.floor((max_diff_z + max_z)/ her.binwidth_z + 1) # edge <= x < edge\n",
    "    her.n_bins_z = int(n_bins_left+n_bins_right)\n",
    "    mini = -her.binwidth_z*n_bins_left\n",
    "    maxi =  her.binwidth_z*n_bins_right\n",
    "    her.edges_z = np.linspace(mini, maxi, her.n_bins_z+1) # edges of the z+diff_z pmf\n",
    "    pmf_z_all_obs, _ = np.histogram(z_cal, bins=her.edges_z, density=True) # calculate the z PMF of the full dataset \n",
    "    her.bin_centers_edges_z = her.edges_z[:-1] + her.binwidth_z/2\n",
    "    her.bin_centers_edges_diff_z = her.edges_diff_z[:-1] + her.binwidth/2\n",
    "    \n",
    "    return her\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
