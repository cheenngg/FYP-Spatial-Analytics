{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e128b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f_her_predict(x_cal, y_cal, z_cal, x_target, y_target, her):\n",
    "    # Step 1: Distance of the target to its neighbors\n",
    "    mat_euc_distance_obs_target_pred = np.empty((len(x_cal), len(x_target)))\n",
    "    for target in range(len(x_target)):\n",
    "        for obs in range(len(x_cal)):\n",
    "            mat_euc_distance_obs_target_pred[obs, target] = f_euclidean_dist(x_target[target], y_target[target], x_cal[obs], y_cal[obs])\n",
    "    \n",
    "    # Step 2: Identify the class of each neighbor\n",
    "    classes_obs_target_pred = np.zeros((len(x_cal), len(x_target)))\n",
    "    for target in range(len(x_target)):\n",
    "        for obs in range(len(x_cal)):\n",
    "            for class_ in range(her['n_classes_range']):\n",
    "                if mat_euc_distance_obs_target_pred[obs, target] > her['edges_distance_classes_range'][class_] and mat_euc_distance_obs_target_pred[obs, target] <= her['edges_distance_classes_range'][class_+1]:\n",
    "                    classes_obs_target_pred[obs, target] = class_\n",
    "            if mat_euc_distance_obs_target_pred[obs, target] == 0:\n",
    "                classes_obs_target_pred[obs, target] = 1\n",
    "            if mat_euc_distance_obs_target_pred[obs, target] > her['edges_distance_classes_range'][class_+1]:\n",
    "                classes_obs_target_pred[obs, target] = her['n_classes_range'][-1]\n",
    "    \n",
    "    n_obs_by_class_pred, edgge_class = np.histogram(classes_obs_target_pred.flatten(), bins=np.arange(-0.5, her['n_classes_range']+1, 1))\n",
    "    target_idx_zero_neigh_pred = [target for target in range(len(x_target)) if n_obs_by_class_pred[-1, target] == np.sum(n_obs_by_class_pred[1:, target])]\n",
    "    \n",
    "    idx_nn = np.empty((her['n_neighbor'], len(z_cal)))\n",
    "    mat_euc_distance_obs_target_pred_nn = np.empty((her['n_neighbor'], len(z_cal)))\n",
    "    classes_obs_target_pred_nn = np.empty((her['n_neighbor'], len(z_cal)))\n",
    "    z_cal_nn = np.empty((her['n_neighbor'], len(z_cal)))\n",
    "    for target in range(len(x_target)):\n",
    "        idx_ = np.argsort(mat_euc_distance_obs_target_pred[:, target])\n",
    "        idx_nn[:, target] = idx_[:her['n_neighbor']]\n",
    "        mat_euc_distance_obs_target_pred_nn[:, target] = mat_euc_distance_obs_target_pred[idx_nn[:, target], target]\n",
    "        classes_obs_target_pred_nn[:, target] = classes_obs_target_pred[idx_nn[:, target], target]\n",
    "        z_cal_nn[:, target] = z_cal[idx_nn[:, target]]\n",
    "    \n",
    "    # Step 3: Normalized weights\n",
    "    weights_or_pred_nn = np.zeros((her['n_neighbor'], len(x_target)))\n",
    "    normalized_weight_or_pred_nn = np.zeros((her['n_neighbor'], len(x_target)))\n",
    "    weights_or_cont_pred_nn = np.zeros((her['n_neighbor'], len(x_target)))\n",
    "    normalized_weights_or_cont_pred_nn = np.zeros((her['n_neighbor'], len(x_target)))\n",
    "    weights_and_pred_nn = np.zeros((her['n_neighbor'], len(x_target)))\n",
    "    weights_and_cont_pred_nn = np.zeros((her['n_neighbor'], len(x_target)))\n",
    "    for target in range(len(x_target)):\n",
    "        for obs in range(her['n_neighbor']):\n",
    "            weights_or_pred_nn[obs, target] = her['best_w_OR'](classes_obs_target_pred_nn[obs, target])\n",
    "            weights_or_cont_pred_nn[obs, target] = her['best_w_OR'](classes_obs_target_pred_nn[obs, target]) + her['w_OR_slope'](classes_obs_target_pred_nn[obs, target]) * (mat_euc_distance_obs_target_pred_nn[obs, target] - her['edges_distance_classes_range'][classes_obs_target_pred_nn[obs, target]])\n",
    "            weights_and_pred_nn[obs, target] = her['best_w_AND'](classes_obs_target_pred_nn[obs, target])\n",
    "            weights_and_cont_pred_nn[obs, target] = her['best_w_AND'](classes_obs_target_pred_nn[obs, target]) + her['w_AND_slope'](classes_obs_target_pred_nn[obs, target]) * (mat_euc_distance_obs_target_pred_nn[obs, target] - her['edges_distance_classes_range'][classes_obs_target_pred_nn[obs, target]])\n",
    "    \n",
    "    for target in range(len(x_target)):\n",
    "        for obs in range(her['n_neighbor']):\n",
    "            normalized_weight_or_pred_nn[obs, target] = weights_or_pred_nn[obs, target] / np.sum(weights_or_pred_nn[:, target])\n",
    "            normalized_weights_or_cont_pred_nn[obs, target] = weights_or_cont_pred_nn[obs, target] / np.sum(weights_or_cont_pred_nn[:, target])\n",
    "    \n",
    "    # Steps 4: Obtaining the z PMF of the known observations(obs_diff_z + z) & z PMF with aggregation\n",
    "    pmf_pred_nn = [None] * len(x_target)\n",
    "    target_idx_without_AND_pred = []\n",
    "    pmf_z_target_given_neigh_pred_ = np.empty((her['n_neighbor'], her['n_bins_z']))\n",
    "    diff_n_bins_shift = her['n_bins_z'] * her['n_bins_z_per_bin_shift'] - her['n_bins_shift']\n",
    "    for target in range(len(x_target)):\n",
    "        for obs in range(her['n_neighbor']):\n",
    "            class_ = classes_obs_target_pred_nn[obs, target]\n",
    "            bins_shift = round((her['edges_diff_z_shift'][0] + z_cal_nn[obs, target] - her['edges_z'][0]) / her['binwidth_shift'])\n",
    "            idx_bins_shift = np.tile(np.concatenate((np.ones(bins_shift), np.arange(2, her['n_bins_shift']+1), np.ones(int(diff_n_bins_shift) - bins_shift))), (her['n_bins_z_per_bin_shift'], 1))\n",
    "            pmf_ = her['pmf_diff_z_by_class_obs_range_shift'][class_, :]\n",
    "            pmf_z_target_given_neigh_pred_[obs, :] = np.sum(pmf_[idx_bins_shift], axis=0)\n",
    "            pmf_z_target_given_neigh_pred_[obs, :] = pmf_z_target_given_neigh_pred_[obs, :] / np.sum(pmf_z_target_given_neigh_pred_[obs, :])\n",
    "        \n",
    "        idx = np.arange(her['n_neighbor'])\n",
    "        pmfs_ = pmf_z_target_given_neigh_pred_[idx, :]\n",
    "        if her['aggregation_type'] == 'andor':\n",
    "            weights_or_ = normalized_weights_or_cont_pred_nn[idx, target]\n",
    "            weights_and_ = weights_and_cont_pred_nn[idx, target]\n",
    "            pmf_and_ = f_loglinear_aggregation(pmfs_, weights_and_)\n",
    "            pmf_or_ = f_linear_aggregation(pmfs_, weights_or_)\n",
    "            pmf_ = f_loglinear_aggregation(np.concatenate((pmf_and_, pmf_or_)), np.array([her['best_alpha'], her['best_beta']]))\n",
    "            pmf_pred_nn[target] = pmf_\n",
    "        elif her['aggregation_type'] == 'and':\n",
    "            weights_and_ = weights_and_cont_pred_nn[idx, target]\n",
    "            pmf_and_ = f_loglinear_aggregation(pmfs_, weights_and_)\n",
    "            pmf_pred_nn[target] = pmf_and_\n",
    "        elif her['aggregation_type'] == 'or':\n",
    "            weights_or_ = normalized_weights_or_cont_pred_nn[idx, target]\n",
    "            pmf_or_ = f_linear_aggregation(pmfs_, weights_or_)\n",
    "            pmf_pred_nn[target] = pmf_or_\n",
    "    \n",
    "    return pmf_pred_nn, target_idx_zero_neigh_pred\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
